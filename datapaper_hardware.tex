\begin{figure}
  \includegraphics[width=0.93\linewidth,trim=50 80 200 70,clip]{Figures/hardware}
\caption{The hardware setup for our data collection.}
\label{fig:hardware}
\end{figure}

\subsection{Hardware Setup}

In this section, we introduce the hardware used for capturing fluorescence, IR, RGB color, and depth imagery data for both plants.
Figure~\ref{fig:hardware} illustrates the hardware and imaging setup used in our data collection.

\subsubsection{Fluorescence and IR images}
Chlorophyll a fluorescence images were captured once every hour during the daylight period in a growth chamber~\cite{cruz2015depi}. 
A set of $5$ images were captured using a Hitachi KP-F145GV CCD camera (Hitachi Kokusai Electric America Inc., Woodbury, NY) outfitted with an infrared long pass filter (Schott Glass RG-9, Thorlabs, Newton, NJ), during a short period ($<400~ms$) of intense light saturating to photosynthesis ($>10,000~\mu mol~photons~m^{-2} s^{-1}$) provided by an array of white Cree LEDs (XMLAWT, 5700K color temperature, Digi-Key, Thief River Falls, MN) collimated using a $20~mm$ Carclo Lens (10003, LED Supply, Lakewood, CO).
%
Chlorophyll a fluorescence was excited using monochromatic red LEDs (Everlight $625~nm$, ELSH-F51R1-0LPNM-AR5R6, Digi-Key), collimated using a Ledil reflector optic ($C11347\_REGINA$, Mouser Electronics, Mansfield, TX) and pulsed for $50~\mu s$ during a brief window when the white LEDs were electronically shuttered.  
In addition, a series of $5$ images were also collected in the absence of the excitation light for artifact subtraction.

Infrared images were collected once every hour with the same camera and filter used for chlorophyll a fluorescence.  
Pulses of $940~nm$ light were provided by an array of OSRAM LEDs (SFH 4239, Digi-Key), collimated using a Polymer Optics lens (Part no. 170, Polymer Optics Ltd., Berkshire, England).  
Since $940~nm$ light does not influence plant development or drive photosynthesis, images were also collected during the night period.  
Sets of $15$ images were collected for averaging, in the absence of saturating illumination.   
As with chlorophyll a fluorescence, images were captured in the absence of $940~nm$ light for artifact subtraction.

% For one-column wide figures use
\begin{figure}
  \includegraphics[width=\linewidth,trim=50 230 45 300,clip]{Figures/CameraConfiguration}
\caption{A plot of the three cameras showing their relative configuration and fields of view as obtained through calibration.  Units are in $mm$.  The optical center of the color camera (on the left) defines the world coordinate system.  Close to it is the depth camera.  Its points are projected into the world coordinate system.  On the right is the combined fluorescent and IR camera.}
\label{fig:CameraConfiguration}
\end{figure}

\subsubsection{RGB color and depth images} %This section describes characterizes the data from this sensor, particularly the depth data.

The RGB color and depth images were collected using a Creative Senz3D sensor~\cite{nguyen2015vietnamese}. The sensor contains both a $1280 \times 720$ color camera directed parallel to, and separated by roughly $25~mm$ from, a depth camera which has a resolution of $320\times240$ pixels. 
The depth sensor uses a flash near IR illuminator and measures the time-of-flight of the beam at each pixel to obtain dense depth estimates along with an IR reflectance at each pixel.

There are a number of limitations to the depth sensor that become the sources of depth errors. 
The primary measurement limitation on the range-to-target is the strength of the reflected beam. 
As a result, dark, matt surfaces are measured reliably only at a close range on the order of $20$ or $30~cm$.  
Highly reflective surfaces also pose problems with direct reflections leading to saturation and highly unreliable depths.  
In addition reflective surfaces at grazing angles are less reliably measured since little signal is reflected. 
Hence in our data portions of the chamber floor visible in Figure~\ref{fig:CameraConfiguration} are highly reflective and have incorrect depths.  %FIXME
Fortunately the primary goal of the depth measurements are to obtain leaf depths, and plants provide good, roughly Lambertian reflections of IR~\cite{Chelle2006219}.  
Therefore for these reasons the non-leaf depth pixels in the $3$D depth data are unreliable and should be ignored in data analysis.  
Another limitation is that the IR illuminator has a slight offset to the left of the sensor, which results in shadows to the right of some objects, as well as mixed pixels on depth discontinuities.  
Both of these can be readily detected as large standard deviations in the depth image.


The imagery data were collected once every hour. %taken within 10 minutes of each other.  %
These include the fluorescent image, the IR reflectance image with the same camera, the color image, the $3$D depth and a confidence image.  
The $3$D depth image is built from the depth sensor by transforming the points into the world coordinates and is expressed in the unit of $mm$.  
The confidence image is the standard deviation of the depth pixels.  
This is useful for identifying pixels at depth discontinuities that are unreliably detected and result in large standard deviations.  
In addition pixels with no response or saturated pixels are assigned with the maximum standard deviation, and should be filtered out.

\begin{figure}[t!]
\centering
%\begin{tabular}{ c c}
%  \includegraphics[height=5.2cm,trim=160 300 170 310,clip]{Figures/BiasError} &
%  \includegraphics[height=5.2cm,trim=110 240 50 260,clip]{Figures/SigmaRadius} \\
%  (\emph{a}) & (\emph{b}) \\
%\end{tabular}
\begin{tabular}{ c}
  \includegraphics[height=3.8cm,trim=175 310 140 310,clip]{Figures/BiasError} \\
   \small{(a)} \\
  \includegraphics[height=5.9cm,trim=110 250 60 260,clip]{Figures/SigmaRadius} \\
  \small{(b)}  \\
\end{tabular}
\caption{Noise analysis for a depth camera.  (\emph{a}) Bias was fit and we found it to be roughly constant as a function of depth.  This constant offset is shown for the camera pixels with red positive and blue negative offset in mm.  Inside the chamber, the obstructions around the depth camera altered the bias somewhat and we re-calibrated the bias there.  In all cases we subtracted the modeled constant bias from the depth images.  (\emph{b}) The standard deviation of the depth camera depends on depth as well as roughly on radius from the image optical center.  A radius of $200$ pixels corresponds to the corners of the depth camera, which can be seen to have large noise. }
\label{fig:Bias}
\end{figure}

