\section{Conclusion and Discussion}

This paper presents a newly collected multi-modality plant imagery dataset ``MSU-PID''.
It has two subsets for Arabidopsis and bean plants respectively.
Compared to existing databases in the field, MSU-PID uses multiple calibrated modalities including fluorescence, infrared, RGB color, and depth.
Detailed image capture process and camera calibration are studied.
We provide our manual labels about leaf tip locations, leaf segments, and leaf consistency over time on fluorescence modality.
The labels are propagated to other modalities using homograph mapping for Arabidopsis imagery.
Our annotations enable a wide variety of plant image analysis applications.

% Jeff's comments
It should be obvious that all plants in MSU-PID belong to the same genotype and that no treatments were applied to induce phenotypic differences.  
This is because we have chosen to focus on a fundamental issue with visual phenotyping, i.e. accurate and automated identification and tracking of individual leaves over developmental time scales (days to weeks).  
The inherent challenge is that as leaves emerge and grow they change in size, position and shape and they may overlap or be overlapped by other leaves.  
Yet, as emphasized in the introduction, these factors may be important determinants for defining phenotypic differences between/among groups.  
In addition, development of these methods would invaluable for providing data to refine models of photosynthesis in plants with more complex canopies and in canopy systems.  
%It might be noticed that all plants in MSU-PID belong to the same genotype and no treatments applied.
%This is because we think a fundamental issue with visual phenotyping, i.e., accurate and automated identification and tracking of individual leaves over developmental time scales (weeks), whose importance has been highlighted in Section~\ref{sec:intro}, needs to be solved before expending our goal to define group differences.
%The inherent challenge in this issue is that as leaves emerge and grow, they change in size, position and shape and they may overlap or be overlapped by other leaves.
%We emphasize more in leaf segmentation, alignment and tracking rather than developing methods to discriminate group differences.

For others to use our dataset, we have designed an experimental protocol with various evaluation metrics for different applications.
To facilitate future research, we apply our automatic multi-leaf segmentation, alignment, and tracking algorithm on the fluorescence and RGB modalities of Arabidopsis imagery, where the labels for RGB modality is provided via label propagation.
The experimental results on fluorescence and RGB images indicate that our dataset is very challenging.

We believe this new database will be beneficial to the research community in terms of algorithm development, performance evaluation, and identifying new research problems in plant image analysis.
Furthermore, We are also open to suggestions and comments from the users of this database to further enhance our imaging setup and capturing protocol, so that we can develop new databases in the future.

%This paper presents a newly collected multi-modality plant imagery database, ``MSU-PID''.
%Compared to existing databases in the field, MSU-PID not only has multiple calibrated modalities, but also enables a wide variety of plant image analysis applications.
%Therefore, we believe this new database will be beneficial to the research community in terms of algorithm development, performance evaluation, and identifying new research problems in plant image analysis.
%Furthermore, we are also open to suggestions and comments from the users of this database to further enhance our imaging setup and capturing protocol, so that we can develop new databases in the future.
%
%It might be noticed that all plants (respectively for Arabidopsis and bean) in MSU-PID belong to the same genotype and no treatments applied.
%%This would entail that the proposed dataset cannot be used to investigate computer vision algorithms or imaging modalities in relation to group differences. Could the authors comment on this? This is true. We are not comparing group differences, based on morphology (for example).
%This is because we think a fundamental issue with visual phenotyping, i.e. accurate and automated identification and tracking of individual leaves over developmental time scales (weeks), which importance has being highlighted in Introduction, needs to be solved before expending our goal to define group differences. The inherent challenge in this issue is that as leaves emerge and grow, they change in size, position and shape and they may overlap or be overlapped by other leaves.
%%I think that new text we have added more clearly emphasizes leaf identification and tracking over time rather than developing methods/algorithms to define group differences.
%
%
