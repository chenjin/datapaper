\section{Introduction}
\label{sec:intro}

With the rapid growth of world population  and the loss of arable land, there is an increasing desire to improve the yield and quality of crops, where the understanding of the genetic mechanisms to control plant growth is a key enabler~\cite{doos2002population}.
%
For this purpose, plant scientists make various genetic mutant strains of plants, grow them either in  growth chambers with simulated environmental conditions or directly in the field, visually observe the plants during the growth period, and finally discover plant morphological or physiological patterns that tightly associate with key growth factors~\cite{houle2010phenomics}.
%
While many factors can be assessed quantitatively, which is essential for high-throughput study, one of the bottleneck in this research pipeline is plant visual phenotyping~\cite{walter2015plant}.

Plant visual phenotyping aims to analyze and categorize the visual appearance of plants~\cite{}. In old days, this was conducted via manual visual observation~\cite{Erblichkeit1903}. Today, with the increasing lower cost of imaging sensors and advances of computer vision technologies, image-based automatic plant visual phenotyping is growing into a desirable and viable solution~\cite{cruz2015depi}. In this interdisciplinary field, scientists employ various imaging sensors to capture plants and design advanced algorithms to automatically analyze the captured plant imagery, with the goal of raising testable biological hypotheses to solve the aforementioned problems.

Due to diverse variations of leaf appearance, layout, growth and movement, plant image analysis is a non-trivial computer vision task~\cite{}. In order to develop advanced algorithms, image databases that are well representative of this application domain is highly important. In fact, computer vision research lives on and advances with databases, as evidenced by the successful databases in the field (e.g., FERET~\cite{Phillips2000}, LFW~\cite{LFW}, Caltech$101$~\cite{Fei-Fei2004}). However, the publicly available database for plant phenotyping is still limited, with the only exception of LSC database \cite{scharr2014annotated}, which, nevertheless, has its own limitations on the type of images (RGB only), and is only suitable for a small set of applications.

To facilitate future research on plant image analysis, as well as remedy the limitation of existing databases in the field, this paper presents a newly collected multi-modality plant imagery database, termed ``MSU-PID''. The MSU-PID includes the imagery of two types of plants (Arabidopsis and bean), both are widely used in plant research, captured by four types of sensors, i.e. Fluorescence, IR, RGB color, and depth.
%
All four sensors are synchronized and are programmed to periodically capture data for multiple days. Checkerboard-based camera calibration is perform between the multiple sensors, which results in the explicit correspondence between the pixels of any two modalities. For a subset of the database, we manually label the ground truth on the leaf identification number, leaf tip locations and leaf segments. To provide a performance baseline for future comparison, we apply our automatic leaf segmentation approach~\cite{yin2014a,yin2014b} to the Arabidopsis imagery and demonstrate the challenge of image analysis on this database.

In summary, this paper and our database have made the following main contributions.
\begin{itemize}
\item MSU-PID is the first {\it multi-modality} plant image database. This allows researchers to study the strength and weakness of individual modality, as well as their fusion in plant image analysis.
\item Our imaging setup and the variety of manual label make MSU-PID an ideal candidate for evaluating a diverse set of plant image analysis tasks, including leaf segmentation, leaf counting, leaf alignment, leaf tracking, leaf growth prediction.
\end{itemize}




